{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "nREWSkVNN9V7",
        "outputId": "9594bfbe-8c3a-412f-fde5-7e95f4e60c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Created 12.\n",
            "Features (X): [[2, 30], [3, 50], [5, 40], [12, 3], [8, 80], [1, 90], [13, 14], [6, 60], [4, 65], [9, 25], [10, 10], [0, 100]]\n",
            "Labels (Y): [0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
            "Initial Weights: w1=-0.2772, w2=0.4727, bias=0.1962\n",
            " \n",
            "Epoch 100: Total Errors = 2\n",
            "Epoch 200: Total Errors = 2\n",
            "Epoch 300: Total Errors = 3\n",
            "Epoch 400: Total Errors = 3\n",
            "Epoch 500: Total Errors = 2\n",
            "Epoch 600: Total Errors = 2\n",
            "Epoch 700: Total Errors = 2\n",
            "Epoch 800: Total Errors = 3\n",
            "Epoch 900: Total Errors = 2\n",
            "Epoch 1000: Total Errors = 3\n",
            "\n",
            " Training Complete.\n",
            "Final Weights: w1=1.1688, w2=-0.1153, bias=-0.3928\n",
            "\n",
            "Test the Model\n",
            "Enter Study Hours (or 'q' to quit): 2\n",
            "Enter Attendance Percentage: 10\n",
            "The student is likely to PASS.\n",
            "\n",
            "Test the Model\n",
            "Enter Study Hours (or 'q' to quit): 1\n",
            "Enter Attendance Percentage: 5\n",
            "The student is likely to PASS.\n",
            "\n",
            "Test the Model\n",
            "Enter Study Hours (or 'q' to quit): 0\n",
            "Enter Attendance Percentage: 10\n",
            "The student is likely to FAIL.\n",
            "\n",
            "Test the Model\n",
            "Enter Study Hours (or 'q' to quit): ada\n",
            "Invalid input. Please enter valid numbers only.\n",
            "\n",
            "Test the Model\n",
            "Enter Study Hours (or 'q' to quit): -10\n",
            "Enter Attendance Percentage: 2\n",
            "Error: Please enter a valid positive number.\n",
            "\n",
            "Test the Model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-459571603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTest the Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0muser_study_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Study Hours (or 'q' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_study_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Name: Mobarok Hossain Zobaer\n",
        "# ID: 0432220005101029\n",
        "\n",
        "\n",
        "\n",
        "# I used these\n",
        "\n",
        "# ● for loops\n",
        "# ● if–else conditions\n",
        "# ● lists\n",
        "# ● functions\n",
        "# ● user input (input())\n",
        "# ● meaningful print() output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# TASK 1: DATASET CREATION\n",
        "\n",
        "# rule (Study_Hours * 10) + Attendance >= 110\n",
        "# If the result is 110 or higher, the student Passes (1). Otherwise, they Fail (0).\n",
        "# I have generated 12 data points to mix passing and failing scenarios.\n",
        "\n",
        "X = [\n",
        "    [2, 30],\n",
        "    [3, 50],\n",
        "    [5, 40],\n",
        "    [12, 3],\n",
        "    [8, 80],\n",
        "    [1, 90],\n",
        "    [13, 14],\n",
        "    [6, 60],\n",
        "    [4, 65],\n",
        "    [9, 25],\n",
        "    [10, 10],\n",
        "    [0, 100]\n",
        "]\n",
        "\n",
        "# Automatically generating labels (Y) based on the rule\n",
        "Y = []\n",
        "for data in X:\n",
        "    study_score = data[0] * 10\n",
        "    attendance_score = data[1]\n",
        "    if study_score + attendance_score >= 110:\n",
        "        Y.append(1)\n",
        "    else:\n",
        "        Y.append(0)\n",
        "\n",
        "print(f\"Dataset Created {len(X)}.\")\n",
        "print(\"Features (X):\", X)\n",
        "print(\"Labels (Y):\", Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TASK 2: PERCEPTRON INITIALIZATION\n",
        "\n",
        "# Initialize weights randomly (−1 to 1) and use a small learning rate to prevent weight explosion from large input values.\n",
        "w1 = random.uniform(-0.5, 0.5)\n",
        "w2 = random.uniform(-0.5, 0.5)\n",
        "bias = random.uniform(-0.5, 0.5)\n",
        "learning_rate = 0.001\n",
        "\n",
        "print(f\"Initial Weights: w1={w1:.4f}, w2={w2:.4f}, bias={bias:.4f}\\n \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TASK 3: ACTIVATION FUNCTION\n",
        "\n",
        "def step_activation(weighted_sum):\n",
        "    # Returns 1 if the weighted sum is >= 0 (Threshold), else returns 0.\n",
        "    if weighted_sum >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TASK 4: TRAINING LOOP\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_error = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "\n",
        "        # 1. Get current input features\n",
        "        x1 = X[i][0]\n",
        "        x2 = X[i][1]\n",
        "        target = Y[i]\n",
        "\n",
        "        # 2. Calculate Weighted Sum (z = x1*w1 + x2*w2 + b)\n",
        "        z = (x1 * w1) + (x2 * w2) + bias\n",
        "\n",
        "        # 3. Predict Output using Activation Function\n",
        "        prediction = step_activation(z)\n",
        "\n",
        "        # 4. Calculate Error\n",
        "        error = target - prediction\n",
        "        total_error += abs(error)\n",
        "\n",
        "        # 5. Update Weights and Bias (Perceptron Learning Rule)\n",
        "        # New_Weight = Old_Weight + (Learning_Rate * Error * Input)\n",
        "        if error != 0:\n",
        "            w1 = w1 + (learning_rate * error * x1)\n",
        "            w2 = w2 + (learning_rate * error * x2)\n",
        "            bias = bias + (learning_rate * error)\n",
        "\n",
        "\n",
        "\n",
        "    # Print loss every 100 epochs to show progress\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Total Errors = {total_error}\")\n",
        "\n",
        "    # Stop early if converged (no errors)\n",
        "    if total_error == 0:\n",
        "        print(f\"Converged early at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n Training Complete.\\nFinal Weights: w1={w1:.4f}, w2={w2:.4f}, bias={bias:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TASK 5: USER INPUT TESTING\n",
        "\n",
        "while True:\n",
        "    print(\"\\nTest the Model\")\n",
        "    try:\n",
        "        user_study_str = input(\"Enter Study Hours (or 'q' to quit): \")\n",
        "        if user_study_str.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        user_study = float(user_study_str)\n",
        "        user_attendance = float(input(\"Enter Attendance Percentage: \"))\n",
        "\n",
        "        # If study hours OR attendance is negative, print error and restart loop\n",
        "        if user_study < 0 or user_attendance < 0:\n",
        "            print(\"Error: Please enter a valid positive number.\")\n",
        "            continue  # Skips the rest of the code and goes back to 'while True'\n",
        "\n",
        "        if user_attendance > 100:\n",
        "            print(\"Error: Attendance cannot be more than 100%.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate prediction only if inputs are valid\n",
        "        z_score = (user_study * w1) + (user_attendance * w2) + bias\n",
        "        result = step_activation(z_score)\n",
        "\n",
        "        if result == 1:\n",
        "            print(\"The student is likely to PASS.\")\n",
        "        else:\n",
        "            print(\"The student is likely to FAIL.\")\n",
        "\n",
        "    except ValueError:\n",
        "        # This catches things like typing \"abc\" instead of a number\n",
        "        print(\"Invalid input. Please enter valid numbers only.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Short Report**\n"
      ],
      "metadata": {
        "id": "dah3RKMuQ1Db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How the dataset was created\n",
        "\n",
        "I created a dataset of 12 students. I defined a synthetic rule where 'Study Hours' are weighted 10 times more than 'Attendance'.\n",
        "\n",
        "Rule: (Study_Hours * 10) + Attendance >= 110\n",
        "\n",
        "If the sum of (Study * 10) and Attendance was greater than or equal to 110, the label was set to 1 (Pass), otherwise 0 (Fail). This creates a linearly separable dataset suitable for a single perceptron."
      ],
      "metadata": {
        "id": "4gHML0qmQkes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Why the learning rate was chosen\n",
        "\n",
        "I chose a Learning Rate of 0.001. Since the input values for 'Attendance' can be high (up to 100), a standard learning rate like 0.1 would cause the weight updates to be too drastic (0.1 * 100 = 10), causing the model to overshoot the optimal values and fail to converge. A smaller learning rate ensures stable, gradual updates."
      ],
      "metadata": {
        "id": "G8MLiGBxRRpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How they verified the model is learning\n",
        "\n",
        "I verified learning by tracking the total_error variable inside the training loop. Initially, the error count was high. As the epochs progressed, the error count decreased until it hit 0, indicating the perceptron had successfully found a decision boundary to classify all training points correctly."
      ],
      "metadata": {
        "id": "_O6rF4WkS12l"
      }
    }
  ]
}